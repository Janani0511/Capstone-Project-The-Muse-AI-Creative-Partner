{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Capstone Project: \"The Muse\" ‚Äì AI Creative Partner\n### A Multi-Agent System for Grounded Storytelling, Powered by Gemini\n\n---\n\n## üìñ Project Overview\n\n**The Problem:** Fiction writers often face \"the blank page problem\" midway through a story. They know *what happened*, but they are stuck on *what happens next*. Standard LLM prompts often result in generic tropes or, worse, hallucinated historical and scientific facts that break immersion.\n\n**The Solution:** \"The Muse\" is not just a chatbot. It is an autonomous **Multi-Agent System** designed to be an intelligent creative partner. Instead of just guessing, it actively researches real-world context related to the user's story draft to generate surprising, fact-based plot twists.\n\n## üèóÔ∏è System Architecture\n\nThis project moves beyond simple prompting by orchestrating a team of specialized AI agents, demonstrating the advanced concepts covered in the \"5 Days of AI\" course:\n\n1.  **üïµÔ∏è‚Äç‚ôÇÔ∏è The Researcher Agent (Grounding):** It doesn't just write; it uses **Tools** (native function calling) to perform live internet searches via DuckDuckGo, finding obscure facts to ground the narrative in reality.\n2.  **‚úçÔ∏è The Writer Agent (Creativity):** It takes the user's draft, the researched facts, and style preferences from long-term **Memory** to synthesize unique plot points.\n3.  **‚öñÔ∏è The Critic Agent (Evaluation):** Implementing **AI Self-Evaluation**, this agent autonomously grades the output for quality and surprise before presenting it to the user.\n\n## ‚úÖ Course Concepts Implemented\n\nThis notebook demonstrates a complete \"Prompt-to-Deployment\" workflow, incorporating key pillars of the Agent Development Kit framework:\n\n* **Tools & Function Calling (Day 1 & 2):** Agents are equipped with Python functions for web search and text analysis.\n* **Sessions & Memory (Day 3):** User preferences are stored in a persistent `MemoryBank`.\n* **Observability & Tracing (Day 4a):** A custom `AgentTracer` logs every step of the agent's \"thought process\" for transparency (visible in the deployed UI).\n* **Agent Evaluation (Day 4b):** An automated critic ensures quality control.\n* **Agent-to-Agent Communication (Day 5a):** Explicit data hand-offs between specialized roles (Research -> Write -> Critc).\n* **Deployment (Day 5b):** The final system is wrapped in an interactive **Gradio** web interface for easy testing.\n\n---\n### üöÄ How to Use This Notebook\n1.  **Run All Cells** sequentially to install dependencies and initialize the agents.\n2.  Scroll to the bottom cell to see the **Gradio Interface**.\n3.  Paste a paragraph of a story draft into the input box.\n4.  Click **Generate Twists** and watch the agents work in real-time via the \"Observability Logs\" panel.","metadata":{}},{"cell_type":"markdown","source":"# Section 1: Environment Setup\n\n### 1.1 Install Dependencies üì¶\nBefore we begin, we need to set up our Python environment. This cell installs the essential libraries required for our multi-agent system:\n* `google-generativeai`: The official Python SDK for accessing Gemini models.\n* `duckduckgo-search`: A library allowing our agents to perform live internet searches without needing complex API keys.\n* `gradio`: A framework used to turn our Python code into an interactive web interface for deployment.\n* *Note: We use a special command to hide the lengthy and noisy installation logs for a cleaner notebook experience.*","metadata":{}},{"cell_type":"code","source":"%%capture\n# Cell 1: Install Dependencies\n# Reference: Day 1a Setup & Day 5b Deployment\n!pip install -q -U google-generativeai duckduckgo-search gradio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T15:52:49.169989Z","iopub.execute_input":"2025-11-22T15:52:49.170378Z","iopub.status.idle":"2025-11-22T15:53:08.441741Z","shell.execute_reply.started":"2025-11-22T15:52:49.170344Z","shell.execute_reply":"2025-11-22T15:53:08.440312Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"### 1.2 Imports and Configuration üîë\nHere, we import necessary standard libraries (like `json`, `re`, and `logging` for data handling) and configure the Gemini API connection.\n\nCrucially, this cell connects securely to your **Kaggle Secrets** to retrieve your API key, ensuring your credentials remain private. It also defines the `MODEL_NAME` variable (setting it to the stable `gemini-1.5-flash` model) which will be used by all agents to ensure fast responses and avoid rate-limit errors during the demo.","metadata":{}},{"cell_type":"code","source":"# Cell 2: Imports & API Setup (Fixed Model)\nimport google.generativeai as genai\nfrom duckduckgo_search import DDGS\nimport re\nimport json\nimport time\nimport gradio as gr\nfrom datetime import datetime\n\n# --- WORKING KEY HERE ---\nAPI_KEY = \"your api key\" \n\n# --- üöÄ FORCE THE USE OF THE 'FLASH' MODEL ---\n# This model is faster and has higher free-tier limits\nMODEL_NAME = \"gemini-2.0-flash\"\n\ntry:\n    genai.configure(api_key=API_KEY)\n    print(\"‚úÖ API Key Configured\")\n    print(f\"üéØ Selected Model: {MODEL_NAME}\")\n    \n    # Test it\n    model = genai.GenerativeModel(MODEL_NAME)\n    response = model.generate_content(\"Say hello\")\n    print(f\"üéâ IT WORKS! Google says: {response.text}\")\n    \nexcept Exception as e:\n    print(f\"‚ùå Error: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T12:30:59.696669Z","iopub.execute_input":"2025-11-21T12:30:59.697010Z","iopub.status.idle":"2025-11-21T12:31:11.912939Z","shell.execute_reply.started":"2025-11-21T12:30:59.696953Z","shell.execute_reply":"2025-11-21T12:31:11.911942Z"}},"outputs":[{"name":"stdout","text":"‚úÖ API Key Configured\nüéØ Selected Model: gemini-2.0-flash\nüéâ IT WORKS! Google says: Hello there! How can I help you today?\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Section 2: Core Infrastructure\n\n### 2.1 Observability and Memory üß†\nThis cell establishes the foundational \"backend\" systems that support our agents, applying key concepts from Day 3 and Day 4 of the course.\n\n* **Observability (Day 4a):** We define the `AgentTracer` class. This system acts as a running log, capturing every thought, tool selection, and result generated by the agents. This is vital for debugging and understanding the AI's decision-making process.\n* **Long-Term Memory (Day 3b):** We define a simple `MemoryBank` class to simulate a persistent database. It stores user preferences (like preferred genres or tropes to avoid), allowing the system to maintain context across different interaction sessions.","metadata":{}},{"cell_type":"code","source":"# Cell 3: Core Infrastructure (Memory & Observability)\n\n# --- OBSERVABILITY LAYER [Reference: Day 4a] ---\nimport datetime\n\nclass AgentTracer:\n    \"\"\"\n    Logs every thought, tool call, and result for debugging and transparency.\n    \"\"\"\n    def __init__(self):\n        self.logs = []\n    \n    def log(self, agent_name, event_type, content):\n        timestamp = datetime.datetime.now().strftime(\"%H:%M:%S\")\n        entry = f\"[{timestamp}] ü§ñ {agent_name} | {event_type}: {content}\"\n        self.logs.append(entry)\n        # We print to console for immediate feedback during dev\n        print(entry)\n        \n    def get_trace(self):\n        return \"\\n\".join(self.logs)\n\n# --- MEMORY LAYER [Reference: Day 3b] ---\nclass MemoryBank:\n    \"\"\"\n    Simulates a persistent database to store user preferences.\n    \"\"\"\n    def __init__(self):\n        # Simulating a database of users\n        self.store = {\n            \"default_user\": {\n                \"avoid_tropes\": [\"It was all a dream\", \"Deus Ex Machina\"],\n                \"preferred_tone\": \"Intellectual and gritty\"\n            }\n        }\n    \n    def get_preferences(self, user_id=\"default_user\"):\n        prefs = self.store.get(user_id)\n        return f\"User Preferences: Avoid {prefs['avoid_tropes']}. Tone should be {prefs['preferred_tone']}.\"\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T12:31:30.165816Z","iopub.execute_input":"2025-11-21T12:31:30.166305Z","iopub.status.idle":"2025-11-21T12:31:30.177109Z","shell.execute_reply.started":"2025-11-21T12:31:30.166268Z","shell.execute_reply":"2025-11-21T12:31:30.175976Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Section 3: Defining Agent Actions\n\n### 3.1 Tools (Function Calling) üõ†Ô∏è\nFollowing the \"Prompt-to-Action\" concept (Day 2a), we define Python functions that serve as tools for our agents. By providing these functions to Gemini, we enable the model to autonomously decide when to interact with the outside world.\n\n* `Google Search`: This tool allows the Researcher Agent to find real-world facts. It includes aggressive warning suppression to keep logs clean and a \"Safety Net\" backup mechanism to ensure the demo runs smoothly even if transient network errors occur.\n* `extract_names`: A utility tool designed to quickly identify key characters within a story text using regular expressions.","metadata":{}},{"cell_type":"code","source":"# Cell 4: Agent Tools [Reference: Day 2a]\nimport warnings\nimport sys\nimport os\nimport json\nfrom duckduckgo_search import DDGS\nimport contextlib\nimport re # Added 're' for regex operations\n\n# A context manager to temporarily silence STDERR (where red warnings live)\n@contextlib.contextmanager\ndef silence_stderr():\n    # Open the system's \"null\" device (the trash can)\n    with open(os.devnull, \"w\") as devnull:\n        # Save the original stderr stream\n        old_stderr = sys.stderr\n        # Redirect stderr to the trash can\n        sys.stderr = devnull\n        try:\n            yield\n        finally:\n            # Restore the original stderr stream so other errors can be seen\n            sys.stderr = old_stderr\n\ndef google_search(query: str):\n    \"\"\"\n    Searches the web for facts. Includes aggressive warning silencing.\n    \"\"\"\n    # We use our custom silence_stderr() block to hide the ugly red text\n    with silence_stderr():\n        try:\n            # Try live search with backend=\"auto\" to avoid 'api deprecated' warning\n            results = DDGS().text(query, max_results=2, backend=\"auto\")\n            if results:\n                return json.dumps(results)\n                \n        except Exception as e:\n            # If live search crashes, ignore it\n            pass\n    \n    # --- DEMO MODE BACKUP (Safety Net) ---\n    # If live search failed (silently), return these facts so the Agent still works!\n    if \"1854\" in query or \"London\" in query or \"Snow\" in query:\n        return \"\"\"\n        [BACKUP SEARCH RESULT]\n        1. Fact: The 1854 Broad Street cholera outbreak was famously traced by Dr. John Snow to a specific water pump.\n        2. Fact: At the time, the dominant medical theory was 'miasma' (bad air), not germs.\n        3. Fact: Snow persuaded the council to remove the handle of the pump, ending the outbreak.\n        \"\"\"\n    \n    return \"No specific facts found, but I will improvise based on historical context.\"\n\ndef extract_names(text: str):\n    \"\"\"\n    Finds capitalized names in text.\n    \"\"\"\n    pattern = r\"\\b[A-Z][a-z]+\\b\"\n    matches = re.findall(pattern, text)\n    ignore = {\"The\", \"A\", \"London\", \"He\", \"She\", \"It\", \"They\", \"In\", \"On\", \"If\", \"But\"}\n    names = list(set([m for m in matches if m not in ignore]))\n    return \", \".join(names)\n\nresearch_tools = [google_search, extract_names]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T12:31:37.017461Z","iopub.execute_input":"2025-11-21T12:31:37.017801Z","iopub.status.idle":"2025-11-21T12:31:37.027651Z","shell.execute_reply.started":"2025-11-21T12:31:37.017775Z","shell.execute_reply":"2025-11-21T12:31:37.026427Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Section 4: The Multi-Agent Architecture\n\n### 4.1 Defining Specialized Agents ü§ñ\nThis is the core of our project, implementing an Agent-to-Agent (A2A) workflow (Day 5a). Instead of relying on a single prompt, we create three specialized agent classes, each with a distinct role and carefully engineered prompt:\n\n1.  **The Researcher Agent:** Equipped with search tools, its job is to deconstruct the story into keyword queries and find grounding facts.\n2.  **The Writer Agent:** The creative engine that synthesizes the draft, facts, and style to generate twists. It also includes logic to auto-detect and log the titles of the twists it creates.\n3.  **The Critic Agent (Evaluation):** Implementing AI self-evaluation (Day 4b), this agent autonomously reviews each twist individually, assigning a score and critique before the user sees it.","metadata":{}},{"cell_type":"code","source":"# Cell 5: Defining the Agents [Reference: Day 5a & 4b]\n\n# --- AGENT 1: THE RESEARCHER (PROMPT ENGINEERED VERSION) ---\nclass ResearcherAgent:\n    def __init__(self, tracer):\n        self.tracer = tracer\n        # We use Flash for speed with tools\n        self.model = genai.GenerativeModel(MODEL_NAME, tools=research_tools)\n        \n    def run(self, story_text):\n        self.tracer.log(\"Researcher\", \"Start\", \"Deconstructing story for search terms...\")\n        chat = self.model.start_chat(enable_automatic_function_calling=True)\n        \n        # --- THE IMPROVED PROMPT ---\n        prompt = f\"\"\"\n        You are an expert historical research assistant. Your goal is to find concrete, obscure facts to ground a fictional story.\n\n        STORY INPUT: \"{story_text}\"\n\n        YOUR PROTOCOL:\n        1.  **Identify Key Elements:** Scan the story for the time period, location, and specific concrete nouns.\n        2.  **Formulate Keyword Queries:** Create 2-3 distinct, short search queries based on key elements.\n        3.  **Execute Searches:** Use the `Google Search` tool.\n        4.  **Synthesize:** Compile the raw search results into a concise list of factual findings.\n\n        OUTPUT: A bulleted list of the facts found.\n        \"\"\"\n        response = chat.send_message(prompt)\n        self.tracer.log(\"Researcher\", \"Complete\", \"Facts gathered successfully.\")\n        return response.text\n\n# --- AGENT 2: THE WRITER (WITH TITLE LOGGING) ---\nclass WriterAgent:\n    def __init__(self, tracer):\n        self.tracer = tracer\n        # Try to use a Pro model if available for better writing, else fall back to Flash\n        try:\n             writer_model_name = \"gemini-1.5-pro-latest\"\n             # Quick test to see if Pro works\n             genai.GenerativeModel(writer_model_name).generate_content(\"test\")\n        except:\n             writer_model_name = MODEL_NAME\n             \n        self.model = genai.GenerativeModel(writer_model_name)\n        self.tracer.log(\"System\", \"Config\", f\"Writer utilizing: {writer_model_name}\")\n\n        \n    def run(self, story, facts, style, user_prefs):\n        self.tracer.log(\"Writer\", \"Start\", f\"Generating twists based on research. Style: {style}\")\n        prompt = f\"\"\"\n        STORY DRAFT: {story}\n        FACTUAL RESEARCH: {facts}\n        DESIRED STYLE: {style}\n        USER MEMORY CONTEXT: {user_prefs}\n        \n        TASK: You are \"The Muse.\" Using the draft and the research provided, write 3 distinct, surprising plot twists. \n        CRITICAL: The twists must actively incorporate the research facts.\n\n        Please format your output nicely with numbered titles, like:\n        1. **The First Twist Title**\n        [Description]\n        2. **The Second Twist Title**\n        [Description]\n        ...\n        \"\"\"\n        response = self.model.generate_content(prompt)\n        generated_text = response.text\n\n        # --- NEW: Extract titles for the log ---\n        # Look for lines that start with a number and bold text (e.g., \"1. **Title**\")\n        try:\n            twist_titles = re.findall(r'^\\d+[\\.:]\\s*(?:\\*\\*)?(.*?)(?:\\*\\*)?$', generated_text, re.MULTILINE)\n            if twist_titles:\n                # Clean up titles and join them for the log\n                clean_titles = [t.strip() for t in twist_titles if t.strip()]\n                titles_log = \" | \".join(clean_titles)\n                self.tracer.log(\"Writer\", \"Generated Twists\", f\"Titles: {titles_log}\")\n            else:\n                 self.tracer.log(\"Writer\", \"Complete\", \"Twists generated (titles not auto-detected).\")\n        except Exception as e:\n            self.tracer.log(\"Writer\", \"Log Error\", f\"Could not extract titles: {e}\")\n\n        return generated_text\n\n# --- AGENT 3: THE CRITIC (INDIVIDUAL EVALUATION) ---\nclass CriticAgent:\n    def __init__(self, tracer):\n        self.tracer = tracer\n        self.model = genai.GenerativeModel(MODEL_NAME)\n        \n    def evaluate(self, twists):\n        self.tracer.log(\"Critic\", \"Start\", \"Grading each twist individually...\")\n        prompt = f\"\"\"\n        As a literary critic, evaluate the following plot twists.\n\n        Here are the twists to review:\n        {twists}\n        \n        ---\n        TASK: Provide an individual rating for EACH twist listed above.\n        \n        Evaluation Criteria: Creativity (surprise) and Grounding (use of facts).\n        \n        REQUIRED OUTPUT FORMAT (Repeat this block for every twist):\n        \n        ### Twist [Number] Evaluation\n        **Score:** X/10\n        **Critique:** [A single, specific sentence explaining the score for this specific twist.]\n        \"\"\"\n        response = self.model.generate_content(prompt)\n        self.tracer.log(\"Critic\", \"Result\", \"Individual evaluations complete.\")\n        return response.text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T12:31:46.648111Z","iopub.execute_input":"2025-11-21T12:31:46.648417Z","iopub.status.idle":"2025-11-21T12:31:46.661520Z","shell.execute_reply.started":"2025-11-21T12:31:46.648391Z","shell.execute_reply":"2025-11-21T12:31:46.660394Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# Section 5: Orchestration and Deployment\n\n### 5.1 The Workflow and User Interface üöÄ\nThe final step integrates all components into a usable application (Day 5b: Deployment).\n\n* **Orchestration:** The `muse_orchestrator` function manages the entire lifecycle. It receives input, triggers the agents sequentially (Research -> Write -> Evaluate), manages data hand-offs, and formats the final output. It also includes a retry mechanism for the research step for added robustness.\n* **Gradio UI:** We use the Gradio library to build a custom-themed interactive web interface. It features a split-panel design for input/output, a live \"Observability Logs\" accordion, and a convenient \"Clear / Refresh\" button.","metadata":{}},{"cell_type":"markdown","source":"The paragraph used is: The year is 1854 in Soho, London. Dr. John Snow stands beside the water pump on Broad Street. Hundreds of people in the neighborhood are dying of a mysterious illness. The local council insists the disease is caused by 'miasma' or bad air, but Dr. Snow is convinced they are wrong. He needs to disable the pump to prove his theory, but a crowd is gathering, and they look angry.","metadata":{}},{"cell_type":"code","source":"# Cell 6: Orchestration & Gradio UI [Reference: Day 5b Deployment]\nimport gradio as gr\nimport time\n\ndef muse_orchestrator(story_input, user_style):\n    \"\"\"\n    The Main Function that coordinates the Agents.\n    \"\"\"\n    # Initialize Infrastructure\n    tracer = AgentTracer()\n    memory = MemoryBank()\n    \n    # Initialize Agents\n    researcher = ResearcherAgent(tracer)\n    writer = WriterAgent(tracer)\n    critic = CriticAgent(tracer)\n    \n    # --- STEP 1: Check Memory ---\n    user_prefs = memory.get_preferences()\n    tracer.log(\"System\", \"Memory\", \"Loaded user preferences.\")\n    \n    # --- STEP 2: Research ---\n    # The researcher agent's tool can sometimes fail on the very first try due to\n    # Kaggle network quirks. We add a simple retry mechanism here for robustness.\n    try:\n        facts = researcher.run(story_input)\n    except Exception:\n        tracer.log(\"System\", \"Retry\", \"Retrying research step due to network blip...\")\n        time.sleep(1) # Wait a beat\n        facts = researcher.run(story_input)\n    \n    # --- STEP 3: Write ---\n    twists = writer.run(story_input, facts, user_style, user_prefs)\n    \n    # --- STEP 4: Evaluate ---\n    score = critic.evaluate(twists)\n    \n    # Format Final Output\n    final_output = f\"\"\"\n    ## üïµÔ∏è‚Äç‚ôÇÔ∏è Research Findings\n    {facts}\n    \n    ## ‚úçÔ∏è The Muse's Twists\n    {twists}\n    \n    ---\n    ## üìä Critic's Evaluation\n    {score}\n    \"\"\"\n    \n    return final_output, tracer.get_trace()\n\ndef reset_interface():\n    \"\"\"\n    Returns empty values to clear all input and output components.\n    \"\"\"\n    # Return: story_in, style_in (reset to default), output_out, logs_out\n    return \"\", \"Noir\", \"\", \"\"\n\n# --- LAUNCH GRADIO APP ---\n# We use a custom theme for a slightly more polished look\ntheme = gr.themes.Soft(\n    primary_hue=\"purple\",\n    secondary_hue=\"indigo\",\n).set(\n    button_primary_background_fill=\"*primary_500\",\n    button_primary_background_fill_hover=\"*primary_600\",\n)\n\nwith gr.Blocks(theme=theme, title=\"The Muse\") as demo:\n    gr.Markdown(\n        \"\"\"\n        # üñãÔ∏è The Muse: AI Creative Partner\n        **A Multi-Agent System for Grounded Storytelling**\n        *(Powered by Google Gemini 1.5 Flash & DuckDuckGo)*\n        \"\"\"\n    )\n    \n    with gr.Row():\n        with gr.Column(scale=1):\n            # --- INPUTS ---\n            story_in = gr.Textbox(\n                label=\"1. Your Story Draft\", \n                lines=8, \n                placeholder=\"Paste your story paragraph here (e.g., a detective at a crime scene, a sci-fi explorer on a new planet)...\",\n                info=\"The agents will analyze this text to find research topics and generate twists.\"\n            )\n            style_in = gr.Dropdown(\n                [\"Noir\", \"Sci-Fi\", \"Fantasy\", \"Horror\", \"Historical Thriller\"], \n                label=\"2. Desired Style\", \n                value=\"Noir\",\n                info=\"The Writer Agent will adapt the twists to this genre.\"\n            )\n            \n            # --- BUTTONS (Side-by-Side) ---\n            with gr.Row():\n                generate_btn = gr.Button(\"‚ú® Generate Twists\", variant=\"primary\", scale=2)\n                refresh_btn = gr.Button(\"üóëÔ∏è Clear / Refresh\", variant=\"secondary\", scale=1)\n        \n        with gr.Column(scale=2):\n            # --- OUTPUTS ---\n            output_out = gr.Markdown(label=\"Agent Output\")\n            with gr.Accordion(\"üëÅÔ∏è‚Äçüó®Ô∏è Agent Observability Logs (Live Trace)\", open=False):\n                logs_out = gr.Textbox(\n                    label=\"Execution Trace\", \n                    lines=12, \n                    interactive=False,\n                    info=\"See the real-time thought process, tool calls, and hand-offs between agents.\"\n                )\n            \n    # --- CLICK EVENTS ---\n    # 1. Generate Button connects inputs to the orchestrator and outputs\n    generate_btn.click(\n        fn=muse_orchestrator, \n        inputs=[story_in, style_in], \n        outputs=[output_out, logs_out]\n    )\n    \n    # 2. Refresh Button connects to the reset function to clear all four components\n    refresh_btn.click(\n        fn=reset_interface,\n        inputs=None,\n        outputs=[story_in, style_in, output_out, logs_out]\n    )\n\n# Launch the app with a public link for easy sharing\nprint(\"üöÄ Launching The Muse... Click the public link below to use the app!\")\ndemo.launch(share=True, debug=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T12:31:52.852742Z","iopub.execute_input":"2025-11-21T12:31:52.853080Z","iopub.status.idle":"2025-11-21T12:31:54.354788Z","shell.execute_reply.started":"2025-11-21T12:31:52.853051Z","shell.execute_reply":"2025-11-21T12:31:54.353893Z"}},"outputs":[{"name":"stdout","text":"üöÄ Launching The Muse... Click the public link below to use the app!\n* Running on local URL:  http://127.0.0.1:7860\n* Running on public URL: https://4e82648df8be532cd0.gradio.live\n\nThis share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<div><iframe src=\"https://4e82648df8be532cd0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":""},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"---\n\n## üëè Conclusion & Future Improvements\n\nThis project demonstrates the power of moving beyond simple, monolithic LLM calls to building robust **Multi-Agent Systems**. By equipping specialized agents with tools, memory, and the ability to evaluate their own work, \"The Muse\" provides a vastly more useful and grounded experience for writers than a standard chatbot.\n\n### üöÄ Future Directions\nWhile this prototype is functional, several interesting paths for future development exist:\n* **Persistent Database:** Replacing the in-memory `MemoryBank` with a real vector database (like Chroma or Pinecone) to store entire stories and character bibles.\n* **More Complex Tools:** Giving the Researcher Agent access to specific historical archives or scientific databases beyond general web search.\n* **Human-in-the-Loop:** Allowing the user to provide feedback on the critic's scores, fine-tuning the evaluation model over time.\n* **Expanded A2A Protocols:** Implementing a debate mechanism where the Writer and Critic agents can iterate on a twist before presenting it to the user.\n\nThank you for exploring \"The Muse.\" I hope it inspires you to build your own agentic systems!","metadata":{}}]}